{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjQ_OfVyOOCw"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# Diffusion using DDPM on MNIST\n",
        "# -----------------------------\n",
        "\n",
        "import math, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Device: make sure RUNTIME = H100 GPU or A100 GPU\n",
        "# -----------------------------\n",
        "\n",
        "def set_seed(seed=2026):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(0)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device, \"| GPU:\", torch.cuda.get_device_name(0) if device.type == \"cuda\" else \"None\")\n"
      ],
      "metadata": {
        "id": "2I8sme3jOQJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Data (MNIST, grayscale, normalized to [-1, 1])\n",
        "# -----------------------------\n",
        "\n",
        "IMG_SIZE = 32  # use 32x32 for clean down/up sampling\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "tfm = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),  # [0,1] -> [-1,1]\n",
        "])\n",
        "\n",
        "train_ds = datasets.MNIST(root=\"./data\", train=True, download=True, transform=tfm)\n",
        "train_loader = DataLoader(\n",
        "    train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "    num_workers=0, pin_memory=(device.type == \"cuda\"), drop_last=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "nkj_0LjIOdTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Diffusion schedule (linear betas_t)\n",
        "# -----------------------------\n",
        "\n",
        "T = 400\n",
        "beta_start, beta_end = 1e-4, 0.02\n",
        "\n",
        "# NOISE SCHEDULE\n",
        "betas = torch.linspace(beta_start, beta_end, T, device=device)              # [T]\n",
        "alphas = 1.0 - betas                                                       # [T]\n",
        "alpha_bar = torch.cumprod(alphas, dim=0)                                   # [T]\n",
        "alpha_bar_prev = torch.cat([torch.ones(1, device=device), alpha_bar[:-1]]) # [T]\n",
        "\n",
        "# FORWARD COEFFICIENTS\n",
        "sqrt_alpha_bar = torch.sqrt(alpha_bar)\n",
        "sqrt_one_minus_alpha_bar = torch.sqrt(1.0 - alpha_bar)\n",
        "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
        "\n",
        "# REVERSE COEFFICIENTS\n",
        "posterior_variance = betas * (1.0 - alpha_bar_prev) / (1.0 - alpha_bar)\n",
        "posterior_variance = torch.clamp(posterior_variance, min=1e-20)\n",
        "\n",
        "def extract(a_1d, t, x_shape):\n",
        "    # a_1d: [T], t: [B] long -> returns [B,1,1,1] for broadcasting\n",
        "    out = a_1d.gather(0, t)\n",
        "    return out.view(-1, 1, 1, 1)\n",
        "\n",
        "def q_sample(x0, t, noise):\n",
        "    # x_t = sqrt(alpha_bar_t)*x0 + sqrt(1-alpha_bar_t)*eps\n",
        "    return extract(sqrt_alpha_bar, t, x0.shape) * x0 + extract(sqrt_one_minus_alpha_bar, t, x0.shape) * noise\n"
      ],
      "metadata": {
        "id": "I_KNl2aTOelh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# UNet with time embedding\n",
        "# -----------------------------\n",
        "\n",
        "def timestep_embedding(timesteps, dim, max_period=10000):\n",
        "    \"\"\"Sinusoidal timestep embeddings. timesteps: [B] -> [B, dim].\"\"\"\n",
        "    half = dim // 2\n",
        "    freqs = torch.exp(\n",
        "        -math.log(max_period) * torch.arange(0, half, dtype=torch.float32, device=timesteps.device) / half\n",
        "    )\n",
        "    args = timesteps.float()[:, None] * freqs[None]\n",
        "    emb = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "    if dim % 2 == 1:\n",
        "        emb = F.pad(emb, (0, 1))\n",
        "    return emb\n",
        "\n",
        "def _gn_groups(ch: int) -> int:\n",
        "    # pick a GroupNorm group count that divides ch\n",
        "    for g in (32, 16, 8, 4, 2, 1):\n",
        "        if ch % g == 0:\n",
        "            return g\n",
        "    return 1\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, temb_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        g1 = _gn_groups(in_ch)\n",
        "        g2 = _gn_groups(out_ch)\n",
        "        self.norm1 = nn.GroupNorm(g1, in_ch)\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
        "        self.norm2 = nn.GroupNorm(g2, out_ch)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
        "        self.temb_proj = nn.Linear(temb_dim, out_ch)\n",
        "        self.skip = nn.Identity() if in_ch == out_ch else nn.Conv2d(in_ch, out_ch, 1)\n",
        "\n",
        "    def forward(self, x, temb):\n",
        "        h = self.conv1(F.silu(self.norm1(x)))\n",
        "        h = h + self.temb_proj(F.silu(temb))[:, :, None, None]\n",
        "        h = self.conv2(self.dropout(F.silu(self.norm2(h))))\n",
        "        return h + self.skip(x)\n",
        "\n",
        "class AttnBlock(nn.Module):\n",
        "    \"\"\"Simple full attention over spatial positions (good at 8x8 / 16x16).\"\"\"\n",
        "    def __init__(self, ch, num_heads=4):\n",
        "        super().__init__()\n",
        "        assert ch % num_heads == 0\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = ch // num_heads\n",
        "        self.norm = nn.GroupNorm(_gn_groups(ch), ch)\n",
        "        self.qkv = nn.Conv2d(ch, 3 * ch, 1)\n",
        "        self.proj = nn.Conv2d(ch, ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        n = h * w\n",
        "        x0 = x\n",
        "        x = self.norm(x)\n",
        "        qkv = self.qkv(x)  # [B, 3C, H, W]\n",
        "        q, k, v = qkv.chunk(3, dim=1)\n",
        "\n",
        "        # [B, heads, head_dim, N]\n",
        "        q = q.view(b, self.num_heads, self.head_dim, n)\n",
        "        k = k.view(b, self.num_heads, self.head_dim, n)\n",
        "        v = v.view(b, self.num_heads, self.head_dim, n)\n",
        "\n",
        "        # attention: [B, heads, N, N]\n",
        "        scale = 1.0 / math.sqrt(self.head_dim)\n",
        "        attn = torch.softmax((q.transpose(-2, -1) @ k) * scale, dim=-1)\n",
        "        out = (attn @ v.transpose(-2, -1)).transpose(-2, -1)  # [B, heads, head_dim, N]\n",
        "        out = out.reshape(b, c, h, w)\n",
        "        out = self.proj(out)\n",
        "        return x0 + out\n",
        "\n",
        "class BiggerUNet(nn.Module):\n",
        "    \"\"\"\n",
        "    32x32: 32 -> 16 -> 8 -> 4 bottleneck, 2 ResBlocks per level, attention at 16 & 8.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_ch=1, base=96, temb_dim=512, dropout=0.1, attn_heads=4):\n",
        "        super().__init__()\n",
        "        self.temb_dim = temb_dim\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            nn.Linear(temb_dim, temb_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(temb_dim, temb_dim),\n",
        "        )\n",
        "\n",
        "        self.in_conv = nn.Conv2d(in_ch, base, 3, padding=1)\n",
        "\n",
        "        # Down: 32 -> 16 -> 8 -> 4\n",
        "        self.d1a = ResBlock(base, base, temb_dim, dropout)\n",
        "        self.d1b = ResBlock(base, base, temb_dim, dropout)\n",
        "        self.down1 = nn.Conv2d(base, base * 2, 4, stride=2, padding=1)\n",
        "\n",
        "        self.d2a = ResBlock(base * 2, base * 2, temb_dim, dropout)\n",
        "        self.d2b = ResBlock(base * 2, base * 2, temb_dim, dropout)\n",
        "        self.attn16 = AttnBlock(base * 2, num_heads=attn_heads)\n",
        "        self.down2 = nn.Conv2d(base * 2, base * 4, 4, stride=2, padding=1)\n",
        "\n",
        "        self.d3a = ResBlock(base * 4, base * 4, temb_dim, dropout)\n",
        "        self.d3b = ResBlock(base * 4, base * 4, temb_dim, dropout)\n",
        "        self.attn8 = AttnBlock(base * 4, num_heads=attn_heads)\n",
        "        self.down3 = nn.Conv2d(base * 4, base * 8, 4, stride=2, padding=1)\n",
        "\n",
        "        # Middle: 4x4\n",
        "        self.m1 = ResBlock(base * 8, base * 8, temb_dim, dropout)\n",
        "        self.m_attn = AttnBlock(base * 8, num_heads=attn_heads)\n",
        "        self.m2 = ResBlock(base * 8, base * 8, temb_dim, dropout)\n",
        "\n",
        "        # Up: 4 -> 8 -> 16 -> 32\n",
        "        self.up3 = nn.ConvTranspose2d(base * 8, base * 4, 4, stride=2, padding=1)\n",
        "        self.u3a = ResBlock(base * 8, base * 4, temb_dim, dropout)  # concat with skip (8x8, base*4)\n",
        "        self.u3b = ResBlock(base * 4, base * 4, temb_dim, dropout)\n",
        "        self.u_attn8 = AttnBlock(base * 4, num_heads=attn_heads)\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(base * 4, base * 2, 4, stride=2, padding=1)\n",
        "        self.u2a = ResBlock(base * 4, base * 2, temb_dim, dropout)  # concat with skip (16x16, base*2)\n",
        "        self.u2b = ResBlock(base * 2, base * 2, temb_dim, dropout)\n",
        "        self.u_attn16 = AttnBlock(base * 2, num_heads=attn_heads)\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(base * 2, base, 4, stride=2, padding=1)\n",
        "        self.u1a = ResBlock(base * 2, base, temb_dim, dropout)      # concat with skip (32x32, base)\n",
        "        self.u1b = ResBlock(base, base, temb_dim, dropout)\n",
        "\n",
        "        self.out_norm = nn.GroupNorm(_gn_groups(base), base)\n",
        "        self.out_conv = nn.Conv2d(base, in_ch, 3, padding=1)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        temb = timestep_embedding(t, self.temb_dim)\n",
        "        temb = self.time_mlp(temb)\n",
        "\n",
        "        h = self.in_conv(x)\n",
        "\n",
        "        # 32x32\n",
        "        h = self.d1a(h, temb)\n",
        "        h = self.d1b(h, temb)\n",
        "        skip32 = h\n",
        "        h = self.down1(h)  # 16x16\n",
        "\n",
        "        # 16x16\n",
        "        h = self.d2a(h, temb)\n",
        "        h = self.d2b(h, temb)\n",
        "        h = self.attn16(h)\n",
        "        skip16 = h\n",
        "        h = self.down2(h)  # 8x8\n",
        "\n",
        "        # 8x8\n",
        "        h = self.d3a(h, temb)\n",
        "        h = self.d3b(h, temb)\n",
        "        h = self.attn8(h)\n",
        "        skip8 = h\n",
        "        h = self.down3(h)  # 4x4\n",
        "\n",
        "        # middle 4x4\n",
        "        h = self.m1(h, temb)\n",
        "        h = self.m_attn(h)\n",
        "        h = self.m2(h, temb)\n",
        "\n",
        "        # up: 4->8\n",
        "        h = self.up3(h)\n",
        "        h = torch.cat([h, skip8], dim=1)\n",
        "        h = self.u3a(h, temb)\n",
        "        h = self.u3b(h, temb)\n",
        "        h = self.u_attn8(h)\n",
        "\n",
        "        # up: 8->16\n",
        "        h = self.up2(h)\n",
        "        h = torch.cat([h, skip16], dim=1)\n",
        "        h = self.u2a(h, temb)\n",
        "        h = self.u2b(h, temb)\n",
        "        h = self.u_attn16(h)\n",
        "\n",
        "        # up: 16->32\n",
        "        h = self.up1(h)\n",
        "        h = torch.cat([h, skip32], dim=1)\n",
        "        h = self.u1a(h, temb)\n",
        "        h = self.u1b(h, temb)\n",
        "\n",
        "        out = self.out_conv(F.silu(self.out_norm(h)))\n",
        "        return out\n",
        "\n",
        "model = BiggerUNet(in_ch=1, base=96, temb_dim=512, dropout=0.1, attn_heads=4).to(device)\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=2e-4)\n"
      ],
      "metadata": {
        "id": "ZNstQ2gnOgNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Training (epsilon prediction objective)\n",
        "# -----------------------------\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "model.train()\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\", leave=True)\n",
        "    running = 0.0\n",
        "    for i, (x0, _) in enumerate(pbar):\n",
        "        x0 = x0.to(device)  # [B,1,32,32] in [-1,1]\n",
        "        t = torch.randint(0, T, (x0.size(0),), device=device, dtype=torch.long)\n",
        "        noise = torch.randn_like(x0)\n",
        "        xt = q_sample(x0, t, noise)\n",
        "\n",
        "        # USE THE MODEL TO PREDICT NOISE IN X_t\n",
        "        pred = model(xt, t)\n",
        "\n",
        "        # loss = l2(predicted_noise, actual_noise)\n",
        "        loss = F.mse_loss(pred, noise)\n",
        "\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        running = 0.95 * running + 0.05 * loss.item() if i > 0 else loss.item()\n",
        "        if (i + 1) % 50 == 0:\n",
        "            pbar.set_postfix(loss=f\"{running:.4f}\")\n",
        "\n",
        "    print(f\"Epoch {epoch}: loss={running:.4f}\")\n"
      ],
      "metadata": {
        "id": "p7ERMnRIOjIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Sampling (DDPM reverse process)\n",
        "# -----------------------------\n",
        "\n",
        "@torch.no_grad()\n",
        "def p_sample_loop(model, n_samples=25):\n",
        "    model.eval()\n",
        "    x = torch.randn(n_samples, 1, IMG_SIZE, IMG_SIZE, device=device)\n",
        "\n",
        "    for i in tqdm(reversed(range(T)), total=T, desc=\"Sampling\", leave=False):\n",
        "        t = torch.full((n_samples,), i, device=device, dtype=torch.long)\n",
        "        eps = model(x, t)\n",
        "\n",
        "        beta_t = extract(betas, t, x.shape)\n",
        "        sqrt_one_minus_ab_t = extract(sqrt_one_minus_alpha_bar, t, x.shape)\n",
        "        sqrt_recip_a_t = extract(sqrt_recip_alphas, t, x.shape)\n",
        "\n",
        "\n",
        "        # μθ(x_t,t) = 1/sqrt(α_t) * (x_t - (β_t / sqrt(1-̄α_t)) * εθ)\n",
        "        model_mean = sqrt_recip_a_t * (x - beta_t * eps / sqrt_one_minus_ab_t)\n",
        "\n",
        "        # TAKE THE REVERSE STEP\n",
        "        if i == 0:\n",
        "            x = model_mean\n",
        "        else:\n",
        "            var = extract(posterior_variance, t, x.shape)\n",
        "            x = model_mean + torch.sqrt(var) * torch.randn_like(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "samples = p_sample_loop(model, n_samples=25)\n",
        "samples = (samples.clamp(-1, 1) + 1) / 2  # to [0,1]\n",
        "\n",
        "grid = make_grid(samples, nrow=5, padding=8)\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(grid.permute(1, 2, 0).squeeze().cpu(), cmap=\"gray\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "uKN9CFtEOlPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8tS5zsahOlyo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}